<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Ceph chapter on </title>
    <link>/docs/ceph/</link>
    <description>Recent content in Ceph chapter on </description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-US</language>
    <lastBuildDate>Tue, 06 Oct 2020 08:49:15 +0000</lastBuildDate><atom:link href="/docs/ceph/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Ceph cluster</title>
      <link>/docs/ceph/administration/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/administration/</guid>
      <description>Cluster Get cluster health $ ceph -s $ ceph health $ ceph -w Get OSD stats $ ceph osd stat Get MON stats $ ceph mon stat Get MDS stats $ ceph mds stat Dump placement group $ ceph pg dump Dump stunked placement group $ ceph pg dump_stuck Get MON quorum status $ ceph quorum_status Monitor Dump monmap $ ceph mon getmap -o &amp;lt;path&amp;gt; Print monmap $ monmaptool --print &amp;lt;monmap_path&amp;gt; </description>
    </item>
    
    <item>
      <title>Ceph configuration</title>
      <link>/docs/ceph/config/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/config/</guid>
      <description>Ceph centralized configuration Dump configuration  ceph config dump Set parameter  ceph config set &amp;lt;who&amp;gt; &amp;lt;name&amp;gt; &amp;lt;value&amp;gt; Help on a particular parameter  ceph config help &amp;lt;parameter&amp;gt; Example:
ceph config help mon_allow_pool_delete mon_allow_pool_delete - allow pool deletions (bool, advanced) Default: false Can update at runtime: true Services: [mon] configuration history  ceph config log Rollbask configuration  ceph config reset &amp;lt;log_to_reset&amp;gt; Assimilation from standart ceph.conf  ceph config assimilate-conf -i &amp;lt;source_conf_file&amp;gt; -o &amp;lt;new_conf_file&amp;gt; </description>
    </item>
    
    <item>
      <title>CRUSH map and rules</title>
      <link>/docs/ceph/crushmap/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/crushmap/</guid>
      <description>CrushMap Get CrushMap
$ ceph osd getcrushmap -o &amp;lt;binary_file&amp;gt; Convert crushMap From binary to text
$ crushtool -d &amp;lt;binary_file&amp;gt; -o &amp;lt;text_file&amp;gt; From text to binary
$ crushtool -c &amp;lt;text_file&amp;gt; -o &amp;lt;binary_file&amp;gt; Set CrushMap $ ceph osd setcrushmap -i &amp;lt;binary_file&amp;gt; Create new bucket $ ceph osd crush add-bucket &amp;lt;name&amp;gt; &amp;lt;type&amp;gt; List of types :
 osd host chassis rack row pdu pod room datacenter region root  Delete bucket $ ceph osd crush remove &amp;lt;bucket&amp;gt; Move object to new bucket $ ceph osd crush move &amp;lt;object&amp;gt; &amp;lt;bucket_type&amp;gt;=&amp;lt;bucket_name&amp;gt; Create new replicated rule $ ceph osd crush rule create-replicated &amp;lt;rule_name&amp;gt; &amp;lt;bucket_location&amp;gt; &amp;lt;bucket_rep&amp;gt; &amp;lt;osd_class&amp;gt; Example will create a replicated rule limited on datacenter dc1 with SSD :</description>
    </item>
    
    <item>
      <title>Pools</title>
      <link>/docs/ceph/pool/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/pool/</guid>
      <description>Pools List pools $ ceph osd pool ls detail Here detail is optionnal
Get pool information $ ceph osd pool get &amp;lt;pool_name&amp;gt; all Delete pool $ ceph osd pool rm &amp;lt;pool_name&amp;gt; &amp;lt;pool_name&amp;gt; --yes-really-really-mean-it Create new replicated pool $ ceph osd pool create &amp;lt;pool_name&amp;gt; &amp;lt;pg_number&amp;gt; $ ceph osd pool set &amp;lt;pool_name&amp;gt; size &amp;lt;replicas_number&amp;gt; Create new erasure coding pool Get erasure coding profile :
$ ceph osd erasure-code-profile get default Or create new erasure coding profile :</description>
    </item>
    
    <item>
      <title>User Management </title>
      <link>/docs/ceph/cephx/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/cephx/</guid>
      <description>List all CephX auth $ ceph auth list Get an user $ ceph auth get-or-create &amp;lt;user&amp;gt; Create an user $ ceph auth get-or-create &amp;lt;user&amp;gt; mon &amp;lt;mon_caps&amp;gt; osd &amp;lt;osd_caps&amp;gt; Update user caps $ ceph auth caps &amp;lt;user&amp;gt; mon &amp;lt;mon_caps&amp;gt; osd &amp;lt;osd_caps&amp;gt; Delete user $ ceph auth caps &amp;lt;user&amp;gt; mon &amp;#39;&amp;#39; osd &amp;#39;&amp;#39; </description>
    </item>
    
    <item>
      <title>OSD</title>
      <link>/docs/ceph/osd/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/osd/</guid>
      <description>OSD Get OSD metadata $ ceph osd metadata &amp;lt;id_osd&amp;gt; Count object store by type $ ceph osd count-metadata osd_objectstore Get all OSDs version $ ceph tell osd.* version Get OSD tree $ ceph osd tree List all OSD device class $ ceph osd crush class ls List OSD by class $ ceph osd crush class ls-osd &amp;lt;class&amp;gt; Remove OSD device class $ ceph osd crush rm-device-class osd.&amp;lt;id_osd&amp;gt; Multiple OSD could be specified at the same time</description>
    </item>
    
    <item>
      <title>MGR</title>
      <link>/docs/ceph/mgr/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/mgr/</guid>
      <description>List modules $ ceph mgr module ls Enable module $ ceph mgr module enable &amp;lt;module&amp;gt; Disable module $ ceph mgr module disable &amp;lt;module&amp;gt; List modules endpoint $ ceph mgr services </description>
    </item>
    
    <item>
      <title>Ceph Benchmark</title>
      <link>/docs/ceph/bench/</link>
      <pubDate>Tue, 13 Oct 2020 15:21:01 +0200</pubDate>
      
      <guid>/docs/ceph/bench/</guid>
      <description>Rados write $ rados bench -p &amp;lt;pool&amp;gt; &amp;lt;time_in_seq&amp;gt; write --no-cleanup Rados sequencial read $ rados bench -p &amp;lt;pool&amp;gt; &amp;lt;time_in_seq&amp;gt; seq Rados random read $ rados bench -p &amp;lt;pool&amp;gt; &amp;lt;time_in_seq&amp;gt; rand RBD Benchmark $ rbd bench-write &amp;lt;image&amp;gt; --pool=&amp;lt;pool_rbd&amp;gt; </description>
    </item>
    
  </channel>
</rss>
